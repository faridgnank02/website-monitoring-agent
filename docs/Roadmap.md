# ðŸ—ºï¸ ROADMAP - Monitor Agent IA

*SystÃ¨me de monitoring de sites web concurrents avec agent IA*

---

## Vue d'ensemble du projet

Ce projet implÃ©mente un systÃ¨me de surveillance automatique de sites web qui prend des instructions en langage naturel (ex: "surveille la page de prix de TechCorp pour les changements de tarifs"). Le systÃ¨me utilise un agent IA pour identifier l'URL correcte et les Ã©lÃ©ments Ã  surveiller, scrape le site deux fois Ã  ~24h d'intervalle avec Firecrawl, compare les versions et envoie une alerte Gmail uniquement en cas de changements significatifs.

---

## âš™ï¸ DÃ©cisions techniques finales

### Stack technologique retenu :
- **Agent IA** : CrewAI avec un seul agent + API Groq (modÃ¨le Mixtral/Llama)
- **Scraper** : Firecrawl uniquement
- **Scheduling** : n8n (workflow orchestration) + APScheduler (backup/fallback)
- **Multi-sites** : Fichier config YAML (3 sites max) - migration vers Sheets en Phase 5
- **Seuil de changement** : 1% par dÃ©faut, configurable par site

### Calcul du seuil de changement expliquÃ© :

Le **seuil** dÃ©termine si un changement est "significatif" et mÃ©rite une notification.

**Formule :**
```
Score de changement = (Nombre de lignes modifiÃ©es / Nombre total de lignes) Ã— 100
```

**Exemple concret :**
```
Contenu original (50 lignes) :
- Ligne 1: Plan Pro: $99/month
- Ligne 2: Plan Enterprise: Contact us
- ... (48 autres lignes)

Contenu nouveau (50 lignes) :
- Ligne 1: Plan Pro: $129/month  â† CHANGÃ‰
- Ligne 2: Plan Enterprise: Contact us
- ... (48 autres lignes)

Score = (1 ligne changÃ©e / 50 lignes total) Ã— 100 = 2%
```

**DÃ©cision :**
- Si score > seuil (ex: 2% > 1%) â†’ **Alerte envoyÃ©e** ðŸ””
- Si score â‰¤ seuil (ex: 0.5% â‰¤ 1%) â†’ **IgnorÃ©** (bruit/changement mineur)

**Pourquoi c'est important :**
- Ã‰viter les faux positifs (ex: changement d'un timestamp â†’ 0.1%)
- Focus sur les changements business-critical (prix, features, etc.)

### n8n : Comment Ã§a marche ?

**n8n** = Outil d'automatisation no-code/low-code (alternative open-source Ã  Zapier)

**Installation locale (recommandÃ© pour apprendre) :**
```bash
# Option 1 : npx (le plus simple)
npx n8n

# Option 2 : Docker
docker run -it --rm \
  --name n8n \
  -p 5678:5678 \
  -v ~/.n8n:/home/node/.n8n \
  n8nio/n8n

# Option 3 : npm global
npm install -g n8n
n8n start
```

**Workflow typique pour ce projet :**
```
[Cron Trigger]       â† DÃ©clenche tous les jours Ã  10h
    â†“
[Execute Command]    â† Lance : python /path/to/main.py
    â†“
[HTTP Request]       â† (Optionnel) Appelle une API de votre script
    â†“
[If/Switch]          â† VÃ©rifie si erreurs
    â†“
[Gmail/Slack]        â† Notification en cas d'erreur
```

**Pourquoi n8n :**
- Interface visuelle pour dÃ©bugger
- Logs intÃ©grÃ©s
- Peut appeler votre script Python via CLI
- Monitoring des exÃ©cutions
- Notifications d'erreurs
- Facile Ã  Ã©tendre (webhooks, Slack, etc.)

**Alternative APScheduler :**
Si n8n est trop complexe au dÃ©but, APScheduler sera notre fallback (tout en Python).

---

## Phase 1 : Architecture & Configuration (Fondations)

### 1.1 Structure du projet

```
monitor_agent/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ .env.example          # Template des variables d'environnement
â”‚   â”œâ”€â”€ settings.py            # Configuration centralisÃ©e
â”‚   â””â”€â”€ sites.yaml             # Configuration des 3 sites Ã  surveiller
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ modules/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ ai_agent.py       # Agent IA (CrewAI + Groq)
â”‚   â”‚   â”œâ”€â”€ firecrawl_scraper.py  # Scraping avec Firecrawl
â”‚   â”‚   â”œâ”€â”€ content_comparator.py # Comparaison de contenus
â”‚   â”‚   â”œâ”€â”€ sheets_manager.py  # Gestion Google Sheets
â”‚   â”‚   â””â”€â”€ gmail_notifier.py  # Notifications email
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ logger.py          # Logging personnalisÃ©
â”‚   â”‚   â””â”€â”€ validators.py      # Validation des donnÃ©es
â”‚   â””â”€â”€ main.py                # Point d'entrÃ©e principal
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_*.py              # Tests unitaires
â”œâ”€â”€ data/
â”‚   â””â”€â”€ logs/                  # Logs d'exÃ©cution
â”œâ”€â”€ n8n/
â”‚   â””â”€â”€ workflows/             # Workflows n8n (JSON)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env                       # Variables d'environnement (Ã  ignorer)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Roadmap.md                 # Ce fichier
â””â”€â”€ README.md
```

### 1.2 Services Ã  configurer

- **Groq API** : Pour l'agent IA (modÃ¨les Mixtral/Llama)
- **CrewAI** : Framework d'orchestration d'agents
- **Firecrawl API** : Pour le scraping avancÃ© (sites JavaScript)
- **Google Sheets API** : Pour le stockage des donnÃ©es
- **Gmail API** : Pour les notifications
- **n8n** : Orchestration de workflows et scheduling

---

## Phase 2 : Modules Core (DÃ©veloppement)

### 2.1 Module AI Agent (`ai_agent.py`)

**ResponsabilitÃ©s :**
- InterprÃ©ter les instructions en langage naturel
- Identifier l'URL cible Ã  partir d'une description
- DÃ©terminer les Ã©lÃ©ments spÃ©cifiques Ã  surveiller
- GÃ©nÃ©rer des sÃ©lecteurs CSS/XPath si nÃ©cessaire

**Exemple d'utilisation :**
```python
instruction = "surveille la page de prix de TechCorp pour les changements de tarifs"
â†’ URL: https://techcorp.com/pricing
â†’ Ã‰lÃ©ments: prix, plans, fonctionnalitÃ©s
```

**FonctionnalitÃ©s clÃ©s :**
- Parsing d'instructions complexes
- RÃ©solution d'URLs ambiguÃ«s
- MÃ©morisation du contexte (historique des surveillances)
- Validation des URLs extraites

---

### 2.2 Module Firecrawl Scraper (`firecrawl_scraper.py`)

**ResponsabilitÃ©s :**
- Appeler l'API Firecrawl avec authentification Bearer
- Extraire le contenu en Markdown ET HTML
- GÃ©rer les erreurs (timeouts, rate limits)
- Nettoyer et normaliser le contenu

**Points techniques :**
- Gestion des sites JavaScript lourds
- Extraction de zones spÃ©cifiques si demandÃ©
- Stockage du contenu brut pour comparaison
- Retry logic avec backoff exponentiel

**Configuration Firecrawl :**
```python
POST https://api.firecrawl.dev/v0/scrape
Headers:
  - Authorization: Bearer {API_KEY}
Body:
  - url: {target_url}
  - formats: ["markdown", "html"]
```

---

### 2.3 Module Content Comparator (`content_comparator.py`)

**ResponsabilitÃ©s :**
- Comparer deux versions de contenu (diff)
- DÃ©tecter les changements significatifs vs bruit
- Ignorer les Ã©lÃ©ments dynamiques (dates, compteurs)
- Calculer un score de similaritÃ©

**Algorithmes possibles :**
- **Diff textuel** : difflib (Python standard)
- **SimilaritÃ© sÃ©mantique** : embeddings (OpenAI/sentence-transformers)
- **DÃ©tection structurelle** : BeautifulSoup pour HTML
- **Hash comparison** : pour dÃ©tection rapide de changements

**CritÃ¨res de changement significatif :**
- Seuil de diffÃ©rence (ex: >5% du contenu)
- Whitelist/blacklist de sÃ©lecteurs
- Exclusion d'Ã©lÃ©ments dynamiques (timestamps, cookies banners)

---

### 2.4 Module Sheets Manager (`sheets_manager.py`)

**ResponsabilitÃ©s :**
- Authentification OAuth2 Google
- CrÃ©er/mettre Ã  jour les onglets "Log" et "Comparison"
- Stocker l'historique des scrapings
- RÃ©cupÃ©rer la version prÃ©cÃ©dente pour comparaison

**Structure des donnÃ©es :**

**Log Sheet :**
| Timestamp | URL | Instruction | Content Hash | Status |
|-----------|-----|-------------|--------------|--------|
| 2025-11-05 10:00 | techcorp.com/pricing | surveille prix | abc123... | success |

**Comparison Sheet :**
| Date | URL | Changes Detected | Diff Summary | Notification Sent |
|------|-----|------------------|--------------|-------------------|
| 2025-11-05 10:00 | techcorp.com/pricing | Yes | Prix plan Pro: $99â†’$129 | Yes |

**API Google Sheets :**
- Utiliser `gspread` ou `google-api-python-client`
- OAuth2 avec service account ou user credentials
- Gestion des quotas (100 requÃªtes/100s par utilisateur)

---

### 2.5 Module Gmail Notifier (`gmail_notifier.py`)

**ResponsabilitÃ©s :**
- Authentification Gmail API
- GÃ©nÃ©rer des emails HTML formatÃ©s
- Envoyer uniquement si changement dÃ©tectÃ©
- Inclure un rÃ©sumÃ© des modifications

**Template email :**
```
Sujet: [Monitor Agent] Changements dÃ©tectÃ©s sur {site_name}

Corps:
ðŸ”” Changements dÃ©tectÃ©s le {timestamp}

ðŸ“ URL surveillÃ©e: {url}
ðŸ“ Instruction: {user_instruction}

ðŸ” RÃ©sumÃ© des changements:
{diff_summary}

ðŸ”— Voir les dÃ©tails: {google_sheets_link}
```

**API Gmail :**
- Authentification OAuth2
- Quotas: 500 emails/jour (utilisateur standard)
- Format MIME pour emails HTML

---

## Phase 3 : Orchestration & Logique MÃ©tier

### 3.1 Workflow principal (`main.py`)

```
1. Recevoir instruction utilisateur
   â†“
2. AI Agent â†’ Extraire URL + Ã©lÃ©ments cibles
   â†“
3. Firecrawl â†’ Scraper le site (contenu actuel)
   â†“
4. Sheets Manager â†’ RÃ©cupÃ©rer version prÃ©cÃ©dente
   â†“
5. Content Comparator â†’ Comparer les versions
   â†“
6. SI changement dÃ©tectÃ©:
   a. Sheets Manager â†’ Logger le changement
   b. Gmail Notifier â†’ Envoyer alerte
   â†“
7. SINON: Logger "aucun changement"
```

**Gestion des erreurs :**
- Chaque module doit avoir son propre error handling
- Logs dÃ©taillÃ©s Ã  chaque Ã©tape
- Notifications d'erreurs critiques
- Continuation du workflow mÃªme si un composant Ã©choue

---

### 3.2 Scheduling (exÃ©cution automatique)

**Options :**

1. **APScheduler (Python)** - RecommandÃ©
   - LÃ©ger, intÃ©grÃ© au code
   - Scheduling flexible (cron-like)
   - Persistence des jobs
   
   ```python
   from apscheduler.schedulers.blocking import BlockingScheduler
   
   scheduler = BlockingScheduler()
   scheduler.add_job(monitor_website, 'interval', hours=24)
   scheduler.start()
   ```

2. **Cron (Linux/Mac)** - Simple
   ```bash
   # ExÃ©cuter tous les jours Ã  10h
   0 10 * * * cd /path/to/project && python src/main.py
   ```

3. **Celery** - Pour tÃ¢ches distribuÃ©es
   - Plus complexe, nÃ©cessite Redis/RabbitMQ
   - IdÃ©al pour scaling

4. **n8n** - No-code (comme template)
   - Interface visuelle
   - IntÃ©grations natives
   - Moins de contrÃ´le programmatique

---

## Phase 4 : Points Critiques Ã  ConsidÃ©rer

### 4.1 SÃ©curitÃ©

- âœ… Stocker les clÃ©s API dans `.env` (jamais dans le code)
- âœ… Utiliser OAuth2 pour Google (pas de mots de passe)
- âœ… Valider toutes les entrÃ©es utilisateur
- âœ… Rate limiting sur les APIs externes
- âœ… Chiffrement des donnÃ©es sensibles dans Sheets
- âœ… .gitignore pour `.env`, credentials, logs

### 4.2 FiabilitÃ©

- âœ… GÃ©rer les erreurs de chaque API (retry logic)
- âœ… Logs dÃ©taillÃ©s pour debug (utiliser `logging` module)
- âœ… Fallback si Firecrawl Ã©choue (scraper basique avec BeautifulSoup?)
- âœ… Notifications d'erreurs critiques (email admin)
- âœ… Health checks rÃ©guliers
- âœ… Timeouts configurables

### 4.3 Performance

- âš ï¸ Firecrawl peut Ãªtre lent (10-30s par page)
- âš ï¸ Limiter le nombre de sites surveillÃ©s simultanÃ©ment
- âš ï¸ Optimiser les comparaisons (hashs avant diff complet)
- âš ï¸ Cache des rÃ©sultats AI Agent (mÃªme instruction = mÃªme URL)
- âš ï¸ Pagination pour historique Sheets (ne pas charger tout)

### 4.4 CoÃ»ts

| Service | Tarification | Limite gratuite | CoÃ»t estimÃ© |
|---------|--------------|-----------------|-------------|
| Firecrawl | ~$0.001-0.01/scrape | Variable | $0.60-6/mois (2 scrapes/jour) |
| OpenAI API | ~$0.002/instruction | $5 crÃ©dit initial | $0.12/mois (2 instructions/jour) |
| Google Sheets | Gratuit | 10M cellules | $0 |
| Gmail API | Gratuit | 500 emails/jour | $0 |
| **Total** | | | **~$1-7/mois** |

### 4.5 PrÃ©cision de dÃ©tection

**Faux positifs Ã  Ã©viter :**
- Timestamps dynamiques
- Cookies banners
- PublicitÃ©s rotatives
- Compteurs de visiteurs
- NumÃ©ros de sessions

**StratÃ©gies :**
- DÃ©finir un seuil de changement (ex: >5% de diffÃ©rence)
- Whitelist de sÃ©lecteurs importants
- Blacklist d'Ã©lÃ©ments Ã  ignorer
- Normalisation du contenu (strip whitespace, lowercase pour certains)

---

## Phase 5 : AmÃ©lioration Continue

### 5.1 Features avancÃ©es

- ðŸ“Š **Dashboard** : Visualiser l'historique des changements (Streamlit/Flask)
- ðŸ”” **Multi-canal** : Notifications Slack/Discord/Telegram en plus de Gmail
- ðŸ¤– **AI Summarization** : RÃ©sumer les changements en langage naturel
- ðŸ“ˆ **Analyse de tendances** : FrÃ©quence des changements, patterns
- ðŸ”„ **Multi-sites parallÃ¨le** : Surveiller plusieurs sites simultanÃ©ment
- ðŸŽ¯ **Surveillance ciblÃ©e** : SÃ©lecteurs CSS personnalisÃ©s
- ðŸ“± **Interface web** : Pour gÃ©rer les surveillances
- ðŸ§ª **Mode test** : Comparer deux URLs arbitraires
- ðŸ“¦ **Export** : TÃ©lÃ©charger historique en CSV/PDF

### 5.2 Tests

**Tests unitaires :**
- Chaque module testÃ© indÃ©pendamment
- Mocking des APIs externes (responses library)
- Couverture de code >80%

**Tests d'intÃ©gration :**
- Workflow complet avec APIs mockÃ©es
- Validation du flux de donnÃ©es entre modules

**Tests end-to-end :**
- Utiliser des sites de dÃ©mo/staging
- VÃ©rifier les notifications rÃ©elles

**Outils recommandÃ©s :**
- `pytest` : Framework de tests
- `pytest-mock` : Mocking
- `responses` : Mock HTTP requests
- `coverage` : Couverture de code

---

## ðŸŽ¯ Ordre de dÃ©veloppement recommandÃ©

### Sprint 1 : Setup (Semaine 1)
1. âœ… CrÃ©er structure de fichiers
2. âœ… Configurer `.gitignore`, `.env.example`
3. âœ… DÃ©finir `requirements.txt`
4. âœ… Setup config centralisÃ©e (`config/settings.py`)

### Sprint 2 : Core Scraping (Semaine 1-2)
5. âœ… ImplÃ©menter Firecrawl scraper
6. âœ… Tester extraction Markdown + HTML
7. âœ… GÃ©rer erreurs et retry logic

### Sprint 3 : Storage (Semaine 2)
8. âœ… ImplÃ©menter Sheets Manager
9. âœ… CRUD basique sur Google Sheets
10. âœ… CrÃ©er templates Log + Comparison

### Sprint 4 : Comparison (Semaine 2-3)
11. âœ… ImplÃ©menter Content Comparator
12. âœ… Algo de diff simple (difflib)
13. âœ… Tester avec exemples rÃ©els

### Sprint 5 : Notifications (Semaine 3)
14. âœ… ImplÃ©menter Gmail Notifier
15. âœ… Template d'email HTML
16. âœ… Tester envoi notifications

### Sprint 6 : AI Agent (Semaine 3-4)
17. âœ… ImplÃ©menter AI Agent
18. âœ… Parser instructions naturelles
19. âœ… Valider extraction d'URLs

### Sprint 7 : Orchestration (Semaine 4)
20. âœ… Assembler tous les modules dans `main.py`
21. âœ… Workflow complet end-to-end
22. âœ… Gestion d'erreurs globale

### Sprint 8 : Automation (Semaine 4-5)
23. âœ… ImplÃ©menter scheduling (APScheduler)
24. âœ… Logs persistants
25. âœ… Tests avec surveillance rÃ©elle 24h

### Sprint 9 : Tests & Polish (Semaine 5)
26. âœ… Tests unitaires
27. âœ… Tests d'intÃ©gration
28. âœ… Documentation README

### Sprint 10 : DÃ©ploiement (Semaine 5-6)
29. âœ… Configurer serveur/cloud (AWS/GCP/Heroku)
30. âœ… Monitoring production
31. âœ… Setup alertes d'erreurs

---

## ðŸ“‹ Checklist avant de coder

### Comptes & APIs
- [ ] CrÃ©er compte Firecrawl + obtenir API key
- [ ] CrÃ©er compte OpenAI/Claude + obtenir API key
- [ ] Configurer Google Cloud Project
- [ ] Activer Google Sheets API
- [ ] Activer Gmail API
- [ ] CrÃ©er OAuth2 credentials (service account)

### DÃ©cisions techniques
- [ ] Choisir AI provider (OpenAI vs Claude)
- [ ] Choisir stratÃ©gie scheduling (APScheduler vs Cron vs n8n)
- [ ] DÃ©finir seuil de changement significatif
- [ ] DÃ©cider format d'instructions utilisateur

### PrÃ©paration
- [ ] PrÃ©parer 3-5 sites de test pour validation
- [ ] CrÃ©er Google Sheet template (Log + Comparison)
- [ ] DÃ©finir structure des logs
- [ ] PrÃ©parer exemples d'instructions

---

## ðŸš€ Prochaines Ã©tapes immÃ©diates

### Questions Ã  clarifier :
1. **AI Provider** : OpenAI ou Claude pour l'agent IA ?
2. **Scheduling** : Python (APScheduler) ou externe (Cron/n8n) ?
3. **Comptes API** : Lesquels sont dÃ©jÃ  configurÃ©s ?
4. **Use cases** : Quels sites voulez-vous surveiller en premier ?

### Actions recommandÃ©es :
1. CrÃ©er la structure de fichiers complÃ¨te
2. Configurer `.env.example` avec toutes les variables
3. GÃ©nÃ©rer `requirements.txt` dÃ©taillÃ©
4. Commencer par le module Firecrawl (le plus critique)

---

## ðŸ“š Ressources utiles

### Documentation APIs
- [Firecrawl API Docs](https://docs.firecrawl.dev)
- [OpenAI API Reference](https://platform.openai.com/docs)
- [Google Sheets API Python](https://developers.google.com/sheets/api/quickstart/python)
- [Gmail API Python](https://developers.google.com/gmail/api/quickstart/python)

### Libraries Python
- `firecrawl-py` : Client Python pour Firecrawl
- `openai` : Client OpenAI
- `anthropic` : Client Claude (Anthropic)
- `gspread` : Google Sheets wrapper
- `google-auth` : OAuth2 Google
- `apscheduler` : Job scheduling
- `python-dotenv` : Gestion .env
- `beautifulsoup4` : HTML parsing (fallback)
- `difflib` : Text comparison (stdlib)
- `pytest` : Testing framework

### Exemples de projets similaires
- [Website Monitor (GitHub)](https://github.com/topics/website-monitoring)
- [n8n Templates](https://n8n.io/workflows)

---

**Version:** 1.0  
**Date:** 5 novembre 2025  
**Statut:** Planning phase
