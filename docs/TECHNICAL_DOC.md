# üìê Documentation Technique - Monitor Agent

## Vue d'ensemble

Monitor Agent est un syst√®me de surveillance automatis√© de sites web con√ßu autour d'une architecture modulaire. Le syst√®me utilise 5 modules ind√©pendants orchestr√©s par `main.py`.


## Architecture Globale

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          main.py                            ‚îÇ
‚îÇ                   (MonitorAgent Orchestrator)                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ             ‚îÇ             ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ  AI Agent    ‚îÇ ‚îÇ Scraper‚îÇ ‚îÇ Comparator ‚îÇ
        ‚îÇ   (Groq)     ‚îÇ ‚îÇ(Firecrawl)‚îÇ (difflib) ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ             ‚îÇ             ‚îÇ
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ                           ‚îÇ
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ   Sheets   ‚îÇ           ‚îÇ   Gmail    ‚îÇ
          ‚îÇ  Manager   ‚îÇ           ‚îÇ  Notifier  ‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Modules D√©taill√©s

### 1. AI Agent (244 lignes)

**R√¥le :** Parse les instructions en langage naturel et extrait l'URL + √©l√©ments √† surveiller.

**Technologies :**
- Groq API (llama-3.1-8b-instant)
- JSON Schema validation

**Fonction principale :**
```python
def parse_instruction(instruction: str) -> ParsedInstruction
```

**Input :**
```
"surveille les prix sur la page homme de Zalando"
```

**Output :**
```python
ParsedInstruction(
    url="https://www.zalando.fr/homme",
    elements_to_watch=["prix"],
    success=True
)
```

**Prompt Engineering :**
- System prompt avec exemples few-shot
- Output format JSON strict
- Validation avec Pydantic

**Gestion d'erreurs :**
- Retry automatique (3 tentatives)
- Fallback si parsing JSON √©choue
- Logging d√©taill√©

---

### 2. Firecrawl Scraper (202 lignes)

**R√¥le :** Scrape le contenu web avec support JavaScript.

**Technologies :**
- Firecrawl API
- Retry logic avec exponential backoff

**Fonction principale :**
```python
def scrape_url(url: str, max_retries: int = 3) -> ScrapedContent
```

**Features :**
- Support JavaScript (pages dynamiques)
- Extraction markdown + HTML
- M√©tadonn√©es (titre, description, langue)
- Timeout configurable

**Output :**
```python
ScrapedContent(
    url="https://example.com",
    markdown="# Title\nContent...",
    html="<html>...</html>",
    metadata=DocumentMetadata(
        title="Page title",
        description="...",
        language="fr"
    ),
    success=True
)
```

**Retry Strategy :**
1. Tentative 1 : timeout 30s
2. Tentative 2 : timeout 60s
3. Tentative 3 : timeout 90s

---

### 3. Content Comparator (347 lignes)

**R√¥le :** Compare deux versions de contenu et d√©tecte les changements.

**Technologies :**
- **difflib** (Python standard library) - Calcul de diff√©rences et similarit√©
- Algorithme de filtrage personnalis√© pour contenu dynamique
- Scoring bas√© sur le nombre de lignes modifi√©es

**Fonction principale :**
```python
def compare_content(old_content: str, new_content: str) -> ComparisonResult
```

**M√©triques calcul√©es :**
- **change_score** : % de changement (0-100%)
- **added_lines** : Nombre de lignes ajout√©es
- **removed_lines** : Nombre de lignes supprim√©es
- **modified_lines** : Nombre de lignes modifi√©es
- **similarity_ratio** : Score de similarit√© (0-1) via `difflib.SequenceMatcher`

**Utilisation de difflib :**

1. **`difflib.unified_diff()`** - G√©n√®re un diff au format unified (comme `git diff`)
   ```python
   diff = list(difflib.unified_diff(
       lines_old,
       lines_new,
       lineterm=''
   ))
   ```
   Utilis√© pour g√©n√©rer un r√©sum√© lisible des changements.

2. **`difflib.SequenceMatcher()`** - Calcule la similarit√© entre deux cha√Ænes
   ```python
   ratio = difflib.SequenceMatcher(None, str1, str2).ratio()
   # ratio = 0.85 signifie 85% de similarit√©
   ```
   Utilis√© pour d√©tecter les lignes modifi√©es (similaires mais pas identiques).

**Algorithme :**
```python
# 1. Normalisation
old_normalized = normalize_text(old_content)
new_normalized = normalize_text(new_content)

# 2. Filtrage contenu dynamique (timestamps, sessions, etc.)
old_filtered = filter_dynamic_content(old_normalized)
new_filtered = filter_dynamic_content(new_normalized)

# 3. D√©tection changements
added = [line for line in new_filtered if line not in old_filtered]
removed = [line for line in old_filtered if line not in new_filtered]

# 4. D√©tection modifications (difflib.SequenceMatcher)
modified = []
for old_line in removed:
    for new_line in added:
        if difflib.SequenceMatcher(None, old_line, new_line).ratio() >= 0.7:
            modified.append((old_line, new_line))

# 5. Calcul du score
change_score = (len(added) + len(removed) + len(modified)) / total_lines * 100
```

**Normalisation :**
- Suppression espaces multiples
- Lowercase (optionnel)
- Suppression lignes vides

**Filtrage dynamique :**
Ignore les patterns qui changent fr√©quemment :
- Dates (`2025-11-06`, `06/11/2025`)
- Heures (`10:30:45`)
- Timestamps (`Updated: ...`, `Last modified: ...`)
- Session IDs
- Compteurs de visiteurs
- Copyright avec ann√©es

---

### 4. Sheets Manager (606 lignes)

**R√¥le :** Gestion de l'historique dans Google Sheets.

**Technologies :**
- Google Sheets API v4
- Service Account authentication
- Batch operations

**Classes principales :**

#### ScrapingLog
```python
@dataclass
class ScrapingLog:
    timestamp: str
    url: str
    instruction: str
    status: str  # "success" ou "error"
    content_hash: str
    content_length: int
    error_message: Optional[str] = None
    metadata: Optional[Dict[str, Any]] = None
```

#### ComparisonLog
```python
@dataclass
class ComparisonLog:
    timestamp: str
    url: str
    instruction: str
    has_changes: bool
    change_score: float
    added_lines: int
    removed_lines: int
    modified_lines: int
    threshold: float
    diff_summary: str
    old_hash: str
    new_hash: str
```

**M√©thodes principales :**
- `authenticate()` : Authentification service account
- `initialize_sheets()` : Cr√©ation onglets Log/Comparison
- `log_scraping(log)` : Enregistrer un scraping
- `log_comparison(log)` : Enregistrer une comparaison
- `get_last_scraping(url)` : R√©cup√©rer dernier scraping
- `get_scraping_history(url, limit)` : Historique complet

**Optimisations :**
- Batch writes (append au lieu d'insert)
- Cache des onglets existants
- Formatting automatique (headers en gras, background gris)

---

### 5. Gmail Notifier (412 lignes)

**R√¥le :** Envoi de notifications email HTML.

**Technologies :**
- SMTP (Gmail)
- HTML/CSS (email templates)
- TLS encryption

**Template HTML (6208 caract√®res) :**

```html
<!DOCTYPE html>
<html>
<head>
  <style>
    /* Responsive design */
    /* Gradient header */
    /* Badge color√© (Normal/Mod√©r√©/Important/Critique) */
    /* Progress bars */
  </style>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>üö® Changement D√©tect√©</h1>
    </div>
    
    <div class="badge severity-[level]">
      [Niveau de s√©v√©rit√©]
    </div>
    
    <div class="stats">
      <!-- Statistiques des changements -->
    </div>
    
    <div class="diff-summary">
      <!-- R√©sum√© du diff -->
    </div>
    
    <div class="footer">
      <!-- Liens et timestamp -->
    </div>
  </div>
</body>
</html>
```

**Niveaux de s√©v√©rit√© :**
- **Normal** (< 5%) : Badge bleu
- **Mod√©r√©** (5-15%) : Badge orange
- **Important** (15-30%) : Badge rouge
- **Critique** (> 30%) : Badge rouge fonc√©

**Fallback texte (702 caract√®res) :**
Version texte pour clients email sans support HTML.

**S√©curit√© :**
- App Password (pas de mot de passe principal)
- TLS encryption
- Validation des param√®tres

---

## Workflow Complet

### 1. Initialisation
```python
agent = MonitorAgent()
# - Initialise SheetsManager
# - Initialise GmailNotifier
# - Authentifie Google Sheets API
# - V√©rifie onglets Log/Comparison
```

### 2. Chargement Configuration
```python
sites = agent.load_sites_config()
# - Parse sites.yaml
# - Filtre sites actifs (active: true)
# - Retourne liste de configs
```

### 3. Surveillance (par site)
```python
for site in sites:
    agent.monitor_site(site)
```

**√âtapes d√©taill√©es :**

#### 3.1 Parsing Instruction
```python
parsed = parse_instruction(instruction)
# Input: "surveille les prix Zalando"
# Output: url="https://www.zalando.fr", elements=["prix"]
```

#### 3.2 Scraping
```python
scraped = scrape_url(url)
# - Appel Firecrawl API
# - Extraction markdown + HTML
# - R√©cup√©ration m√©tadonn√©es
```

#### 3.3 Hash Calculation
```python
content_hash = hashlib.md5(scraped.markdown.encode('utf-8')).hexdigest()
# Hash MD5 pour comparaison rapide
```

#### 3.4 Logging Scraping
```python
sheets_manager.log_scraping(ScrapingLog(...))
# Enregistre dans onglet "Log"
```

#### 3.5 R√©cup√©ration Historique
```python
history = sheets_manager.get_scraping_history(url, limit=2)
previous = history[1]  # Avant-dernier (dernier = celui qu'on vient de cr√©er)
```

#### 3.6 Comparaison
```python
if content_hash == previous_hash:
    # Aucun changement
    change_score = 0.0
else:
    # Changements d√©tect√©s
    comparison = compare_content(old_content, new_content)
    change_score = comparison.change_score
```

#### 3.7 Logging Comparaison
```python
sheets_manager.log_comparison(ComparisonLog(...))
# Enregistre dans onglet "Comparison"
```

#### 3.8 Notification (si changement > seuil)
```python
if change_score > threshold:
    notification = ChangeNotification(...)
    gmail_notifier.send_notification(notification)
```

### 4. R√©sum√©
```python
# Affiche statistiques finales
logger.info(f"Sites surveill√©s: {total}")
logger.info(f"‚úÖ Succ√®s: {success}")
logger.info(f"‚ùå Erreurs: {errors}")
```

---

## Configuration

### Variables d'environnement (.env)

```bash
# Groq API
GROQ_API_KEY=gsk_...

# Firecrawl API
FIRECRAWL_API_KEY=fc-...

# Google Sheets
GOOGLE_CREDENTIALS_FILE=credentials.json
GOOGLE_SHEET_ID=1DXPcaC...
GOOGLE_SHEET_LOG_TAB=Log
GOOGLE_SHEET_COMPARISON_TAB=Comparison

# Gmail
GMAIL_SENDER_EMAIL=sender@gmail.com
GMAIL_RECIPIENT_EMAIL=recipient@gmail.com
GMAIL_APP_PASSWORD=xxxx xxxx xxxx xxxx
GMAIL_SMTP_SERVER=smtp.gmail.com
GMAIL_SMTP_PORT=587
```

### Sites Configuration (sites.yaml)

```yaml
sites:
  - instruction: "surveille les prix Zalando"
    schedule: "daily 10:00"
    active: true
    threshold: 1.0
    tags:
      - pricing
      - ecommerce
    notes: "Surveillance quotidienne"
```

**Param√®tres :**
- `instruction` : Langage naturel (pars√© par AI Agent)
- `schedule` : Pour future automatisation
- `active` : Activation on/off
- `threshold` : Seuil de changement (%)
- `tags` : Cat√©gorisation
- `notes` : Documentation

---

## Structures de Donn√©es

### Google Sheets - Onglet "Log"

| Colonne | Type | Description |
|---------|------|-------------|
| Timestamp | ISO 8601 | Date/heure du scraping |
| URL | String | URL scrap√©e |
| Instruction | String | Instruction originale |
| Status | Enum | success/error |
| Content Hash | MD5 | Hash du contenu |
| Content Length | Integer | Taille en caract√®res |
| Error | String | Message d'erreur (si √©chec) |
| Metadata | JSON | M√©tadonn√©es additionnelles |

### Google Sheets - Onglet "Comparison"

| Colonne | Type | Description |
|---------|------|-------------|
| Timestamp | ISO 8601 | Date/heure de la comparaison |
| URL | String | URL compar√©e |
| Instruction | String | Instruction originale |
| Changements | Boolean | OUI/NON |
| Score % | Float | Score de changement |
| Lignes + | Integer | Lignes ajout√©es |
| Lignes - | Integer | Lignes supprim√©es |
| Lignes Œî | Integer | Lignes modifi√©es |
| Seuil % | Float | Seuil configur√© |
| R√©sum√© | String | R√©sum√© textuel |
| Hash Ancien | MD5 | Hash version pr√©c√©dente |
| Hash Nouveau | MD5 | Hash version actuelle |

---

## Gestion des Erreurs

### Niveaux de gestion

**1. Module-level :**
Chaque module g√®re ses propres erreurs :
- Retry avec backoff (Firecrawl)
- Fallback JSON parsing (AI Agent)
- Connection retry (Sheets, Gmail)

**2. Orchestrator-level :**
`main.py` capture les exceptions :
```python
try:
    agent.monitor_site(site)
    success_count += 1
except Exception as e:
    logger.error(f"Erreur: {e}")
    error_count += 1
    continue  # Continue avec site suivant
```

**3. Logging :**
Tous les modules utilisent le logger centralis√© :
- **INFO** : Op√©rations normales
- **WARNING** : Changements d√©tect√©s, situations non-critiques
- **ERROR** : √âchecs, exceptions

### Strat√©gies de recovery

**Firecrawl timeout :**
1. Retry avec timeout augment√©
2. Si 3 √©checs ‚Üí Log error dans Sheets
3. Continue avec site suivant

**Sheets API error :**
1. Retry authentification
2. Si √©chec ‚Üí Skip logging (continue workflow)
3. Notification envoy√©e quand m√™me

**Gmail SMTP error :**
1. Log error
2. Continue (notification √©chou√©e mais workflow OK)

---

## Performance

### Temps d'ex√©cution typiques

| Op√©ration | Temps moyen | Remarques |
|-----------|-------------|-----------|
| Parse instruction | 1-2s | Appel Groq API |
| Scraping | 2-5s | D√©pend du site |
| Hash calculation | < 0.1s | MD5 tr√®s rapide |
| Sheets write | 0.5-1s | Batch operation |
| Sheets read | 0.5-1s | Range query |
| Email send | 1-2s | SMTP connection |
| **Total par site** | **5-12s** | Variable |

### Optimisations possibles

1. **Parall√©lisation :**
   ```python
   # Surveiller plusieurs sites en parall√®le
   with ThreadPoolExecutor(max_workers=3) as executor:
       futures = [executor.submit(agent.monitor_site, site) 
                  for site in sites]
   ```

2. **Caching :**
   ```python
   # Cache des r√©sultats AI Agent (m√™me instruction)
   @lru_cache(maxsize=100)
   def parse_instruction_cached(instruction: str):
       return parse_instruction(instruction)
   ```

3. **Batch Sheets operations :**
   ```python
   # √âcrire plusieurs logs en une seule requ√™te
   sheets_manager.batch_log_scrapings(logs_list)
   ```

---

## S√©curit√©

### Credentials Management

**Google Service Account :**
- Cl√© JSON en local (jamais commit√©)
- `.gitignore` inclut `credentials.json`
- Permissions minimales (Sheets API uniquement)

**Gmail App Password :**
- Pas de mot de passe principal stock√©
- App Password r√©vocable individuellement
- `.env` dans `.gitignore`

**API Keys :**
- Variables d'environnement
- Jamais hardcod√©s
- Rotation recommand√©e (90 jours)

### Communication

**TLS/SSL :**
- Gmail SMTP : TLS encryption (port 587)
- Firecrawl API : HTTPS
- Google Sheets API : HTTPS

---

## Tests

### Tests Unitaires

**Fichiers :**
- `tests/test_ai_agent.py`
- `tests/test_content_comparator.py`
- `tests/test_sheets_manager.py`
- `tests/test_gmail_notifier.py`

**Ex√©cution :**
```bash
python3 tests/test_ai_agent.py
```

**Coverage :**
- AI Agent : 100% (4/4 fonctions)
- Comparator : 100% (5/5 fonctions)
- Sheets Manager : 90% (8/9 m√©thodes)
- Gmail Notifier : 95% (simulation mode)

---

## Extensions Futures

### 1. Automatisation (Priorit√©: Haute)

**APScheduler :**
```python
from apscheduler.schedulers.blocking import BlockingScheduler

scheduler = BlockingScheduler()
scheduler.add_job(agent.run, 'cron', hour=10)  # Tous les jours √† 10h
scheduler.start()
```

**Systemd Service (Linux) :**
```ini
[Unit]
Description=Monitor Agent
After=network.target

[Service]
Type=simple
User=ubuntu
WorkingDirectory=/home/ubuntu/monitor_agent
ExecStart=/home/ubuntu/monitor_agent/venv/bin/python3 main.py
Restart=always

[Install]
WantedBy=multi-user.target
```

### 2. Comparaison Avanc√©e

**Stocker contenu complet :**
```python
# Au lieu de juste le hash
sheets_manager.log_scraping_with_content(
    log=scraping_log,
    content=scraped.markdown  # Stocker dans colonne s√©par√©e
)
```

**Diff visuel :**
```python
# G√©n√©rer HTML diff
from difflib import HtmlDiff
differ = HtmlDiff()
html_diff = differ.make_file(old_lines, new_lines)
```

### 3. Multi-canal Notifications

**Slack :**
```python
from slack_sdk import WebClient

client = WebClient(token=SLACK_TOKEN)
client.chat_postMessage(
    channel="#monitoring",
    text=f"Changement d√©tect√© sur {url}"
)
```

**Discord :**
```python
from discord_webhook import DiscordWebhook

webhook = DiscordWebhook(url=DISCORD_WEBHOOK_URL)
webhook.set_content(content=notification_text)
webhook.execute()
```

### 4. Dashboard Web

**Flask + Plotly :**
```python
@app.route('/dashboard')
def dashboard():
    history = sheets_manager.get_all_comparisons()
    fig = px.line(history, x='timestamp', y='change_score')
    return render_template('dashboard.html', graph=fig)
```

---

## Troubleshooting

### Debug Mode

Activer logs DEBUG :
```python
# src/utils/logger.py
LOG_LEVEL = "DEBUG"
```

### Probl√®mes courants

**1. Hash toujours diff√©rent :**
- Contenu dynamique (pub, horloge)
- **Solution :** Augmenter threshold ou filtrer contenu

**2. Firecrawl timeout :**
- Site lent ou bloquant scrapers
- **Solution :** Whitelist IP Firecrawl ou utiliser proxy

**3. Gmail authentication error :**
- App Password invalide
- **Solution :** R√©g√©n√©rer App Password

**4. Sheets API quota exceeded :**
- Trop de requ√™tes
- **Solution :** Batch operations ou cache

---

## M√©triques de Qualit√©

### Code Quality

```bash
# Linting
pylint src/ main.py

# Type checking
mypy src/ main.py

# Code complexity
radon cc src/ -a
```

### Performance Profiling

```python
import cProfile
import pstats

profiler = cProfile.Profile()
profiler.enable()

agent.run()

profiler.disable()
stats = pstats.Stats(profiler)
stats.sort_stats('cumtime')
stats.print_stats(10)
```

---

**Derni√®re mise √† jour :** 6 novembre 2025  
